{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4b73b0",
   "metadata": {},
   "source": [
    "# ðŸš€ RAG Chatbot - Google Colab Quick Start\n",
    "\n",
    "This notebook launches your Task-Oriented RAG Chatbot with Mistral 7B on Google Colab's free GPU.\n",
    "\n",
    "**What you'll need to upload:**\n",
    "1. All Python files (data_processor.py, embeddings.py, retriever.py, llm_handler.py, app.py)\n",
    "2. `rag_index.zip` (your pre-built FAISS index)\n",
    "3. `dataset_jsons.zip` (the dataset)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c5beb",
   "metadata": {},
   "source": [
    "## âœ… Step 1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aee970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected! Go to Runtime > Change runtime type > GPU (T4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f4631",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e00e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch transformers sentence-transformers faiss-cpu gradio accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a8175",
   "metadata": {},
   "source": [
    "## ðŸ“¤ Step 3: Upload Files\n",
    "\n",
    "Click \"Choose Files\" and upload:\n",
    "- `data_processor.py`\n",
    "- `embeddings.py`\n",
    "- `retriever.py`\n",
    "- `llm_handler.py`\n",
    "- `app.py`\n",
    "- `rag_index.zip`\n",
    "- `dataset_jsons.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"ðŸ“¤ Upload ALL Python files and the two ZIP files\")\n",
    "print(\"Required files:\")\n",
    "print(\"  - data_processor.py\")\n",
    "print(\"  - embeddings.py\")\n",
    "print(\"  - retriever.py\")\n",
    "print(\"  - llm_handler.py\")\n",
    "print(\"  - app.py\")\n",
    "print(\"  - rag_index.zip\")\n",
    "print(\"  - dataset_jsons.zip\")\n",
    "print()\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"\\nâœ… Uploaded {len(uploaded)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668710b1",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 4: Extract ZIP Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Extract pre-built FAISS index\n",
    "print(\"Extracting rag_index.zip...\")\n",
    "with zipfile.ZipFile('rag_index.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "print(\"âœ… FAISS index extracted\")\n",
    "\n",
    "# Extract dataset\n",
    "print(\"\\nExtracting dataset_jsons.zip...\")\n",
    "with zipfile.ZipFile('dataset_jsons.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('MyFixit-Dataset-master')\n",
    "print(\"âœ… Dataset extracted\")\n",
    "\n",
    "# Verify files\n",
    "print(\"\\nðŸ“ File check:\")\n",
    "print(f\"  faiss_index.bin: {os.path.exists('faiss_index.bin')}\")\n",
    "print(f\"  documents.pkl: {os.path.exists('documents.pkl')}\")\n",
    "print(f\"  Dataset folder: {os.path.exists('MyFixit-Dataset-master/jsons')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6167caa",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 5: Test Retriever (Quick Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import Retriever\n",
    "\n",
    "print(\"Testing retriever...\")\n",
    "retriever = Retriever(top_k=3)\n",
    "\n",
    "test_query = \"How to replace iPhone battery?\"\n",
    "results = retriever.retrieve(test_query)\n",
    "\n",
    "print(f\"\\nâœ… Retriever working! Query: '{test_query}'\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['metadata']['title'][:60]}...\")\n",
    "    print(f\"   Score: {result['similarity_score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6dec7",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 6: Launch Chatbot with Mistral 7B\n",
    "\n",
    "**This will:**\n",
    "- Load Mistral 7B Instruct (4-bit quantized)\n",
    "- Launch Gradio interface\n",
    "- Create a **public link** you can share\n",
    "\n",
    "â±ï¸ Model loading takes ~5-10 minutes first time (downloads 14.5GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import RAGChatbot\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ LAUNCHING RAG CHATBOT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize chatbot (uses Mistral 7B by default)\n",
    "chatbot = RAGChatbot(use_simple_model=False)\n",
    "\n",
    "# Launch with public link\n",
    "print(\"\\nâœ¨ Creating public Gradio link...\")\n",
    "chatbot.launch(share=True, server_port=7860)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Chatbot is LIVE!\")\n",
    "print(\"Click the gradio.live link above to access your chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f719e14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’¡ Alternative: Use Simplified Model (Faster)\n",
    "\n",
    "If Mistral 7B is too slow or you want faster responses, use this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cec7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE: Launch with simplified model (faster, less GPU)\n",
    "# Uncomment below if you want faster responses:\n",
    "\n",
    "# from app import RAGChatbot\n",
    "# chatbot = RAGChatbot(use_simple_model=True)  # Uses smaller model\n",
    "# chatbot.launch(share=True, server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f3eac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Try These Example Queries:\n",
    "\n",
    "Once the chatbot is running, try:\n",
    "\n",
    "- \"How do I replace an iPhone screen?\"\n",
    "- \"My laptop won't turn on. What should I check?\"\n",
    "- \"Steps to replace a phone battery\"\n",
    "- \"Fix broken headphone jack\"\n",
    "- \"How to clean laptop keyboard?\"\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ Troubleshooting\n",
    "\n",
    "### Out of Memory?\n",
    "- Use the simplified model (see alternative above)\n",
    "- Or restart runtime: Runtime > Restart runtime\n",
    "\n",
    "### Slow Loading?\n",
    "- First time downloads ~14.5GB (one-time)\n",
    "- Subsequent loads are faster (~2-3 min)\n",
    "\n",
    "### Files Not Found?\n",
    "- Re-run Step 3 to upload files\n",
    "- Check file names match exactly\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¾ Save Your Session\n",
    "\n",
    "Download outputs to reuse later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Download files to reuse\n",
    "# from google.colab import files\n",
    "# files.download('faiss_index.bin')\n",
    "# files.download('documents.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b0777",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ You're Done!\n",
    "\n",
    "Your RAG chatbot is now running with:\n",
    "- âœ… Mistral 7B Instruct (4-bit quantized)\n",
    "- âœ… FAISS vector search (76,775 documents)\n",
    "- âœ… Public Gradio interface\n",
    "- âœ… Free GPU acceleration\n",
    "\n",
    "Share the public link with anyone! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
